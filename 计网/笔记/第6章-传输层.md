作用范围：进程之间-提供从源主机的某个进程到目的主机某个进程的逻辑通信，而不仅仅是主机到主机
## 6.1 传输服务
传输层向应用层提供的服务
### 6.1.1 提供给上层的服务
1.面向无连接的服务（e.g.UDP）
2.面向连接的服务（e.g.TCP）
### 6.1.2 传输服务原语
1.服务原语

| Primitive    | Packet Sent          | Meaning（含义）     |
| ------------ | -------------------- | --------------- |
| `LISTEN`     | 无（none）              | 阻塞等待，直到有客户端连接为止 |
| `CONNECT`    | `CONNECTION REQ.`    | 客户端主动发起连接请      |
| `SEND`       | `DATA`               | 发送数据包           |
| `RECEIVE`    | 无（none）              | 阻塞直到收到数据        |
| `DISCONNECT` | `DISCONNECTION REQ.` | 发送断开连接请求，释放连接   |
2.封装
传输层发送的是分段，它会被网络层封装进数据包，再被数据链路层封装进帧
[Frame Header | Packet Header | Segment Header | Segment Payload ]
     ↑              ↑               ↑                  ↑
 数据链路层      网络层(IP)     传输层(TCP/UDP)       应用层数据

3.连接、释放状态机
### 6.1.3 Berkeley套接字
TCP使用的套接字原语

|原语|意义与作用|
|---|---|
|**SOCKET**|创建一个 socket 端点（= 套接字），用于后续通信，是网络编程的起点。函数：`int socket(int domain, int type, int protocol);`|
|**BIND**|将 socket 和一个本地地址（IP+端口）绑定。服务器必须绑定；客户端通常由操作系统自动分配端口。函数：`int bind(int sockfd, struct sockaddr *addr, socklen_t addrlen);`|
|**LISTEN**|告诉操作系统我准备好接收连接了，可以设置**等待队列大小**（backlog）。常用于服务器端。函数：`int listen(int sockfd, int backlog);`|
|**ACCEPT**|被动接受一个连接请求，**返回一个新的 socket 用于通信**。原 socket 继续监听。函数：`int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);`|
|**CONNECT**|主动向服务器发起连接（执行三次握手），通常由客户端调用。函数：`int connect(int sockfd, struct sockaddr *addr, socklen_t addrlen);`|
|**SEND**|发送数据。函数：`ssize_t send(int sockfd, const void *buf, size_t len, int flags);`|
|**RECEIVE**|接收数据。函数：`ssize_t recv(int sockfd, void *buf, size_t len, int flags);`|
|**CLOSE**|关闭连接，释放资源。函数：`int close(int sockfd);`|
### 6.1.4 套接字编程实例：Internet文件服务器
code[[ch06.pdf#page=10&selection=8,0,10,16|ch06, p.10]]
## 6.2 传输协议的要素
数据链路层&传输层的环境对比
1.

|          | 数据链路层    | 传输层                          |
| -------- | -------- | ---------------------------- |
| 寻址       | 通常不需要    | 显式寻址                         |
| 建立连接的过程  | 简单       | 复杂                           |
| 网络中的存储能力 | 无        | 延迟和重复数据包                     |
| 复杂程度     | 固定分配就足够了 | 必须管理数量庞大且变化不定的连接<br>必须考虑带宽变化 |
2.图示[[ch06.pdf#page=22&selection=10,0,10,79|ch06, p.22]]

### 6.2.1 寻址
为能够监听连接请求的进程定义相应的传输地址
- 端口
	- 端口号
- 传输服务接入点TSAP：传输层的一个特定端点（TCP/UDP的端口）
- 网络服务接入点NSAP：网络层的一个特定端点
1.多个客户机和服务器可以在具有单个网络（IP）地址的主机上运行
2.端口号：唯一标识主机上的进程
3.IP地址&端口号：IP 地址定位主机，端口号定位进程
- 目标 IP 地址决定了哪台主机接收该数据包
- 目标端口号决定了主机上哪个进程处理数据
4.ICANN范围
16位，范围：0-65535
①知名端口号：0-1023
②注册端口号：1024-49151
③动态/私有端口号：49152-65535
### 6.2.2 连接建立
#### 问题：延迟和重复的数据包
1.关键问题：数据包在传输过程中可能会丢失、损坏、延迟或重复到达
- 不要把旧包或重复包当成新包
- 用ARQ与校验和处理丢失与损坏问题
2.限制包的生存期的技术
- 限制网络规模
- 在每个包中放置一个跳数计数器
- 给每个数据包加时间戳
- 不要在MSL（最大段生存时间）T=240秒的<font color="#c00000">两倍</font>内重用序列号（不仅要保证数据包已过期，还要保证对它的所有确认ack已过期）
2.拒绝【延迟重复段】的方法
①前提条件：数据包的生命周期必须是有限的
②方法：发送方在T秒内不会重复使用相同的序列号；速率和周期T（e.g.2MSL)决定序号空间的大小
③任何时刻，只允许网络中存在一个特定序列号的包；即使有重复包到达，接收方也必须丢弃它们
3.机器在崩溃后丢失所有内存的问题
①解决方案1（不实用）：要求传输实体在恢复后空闲T秒
②解决方案2：利用系统时间生成不重复的序列号，即使主机崩溃重启，也能避免使用重复的序列号
- 给每台主机配备一个时间时钟
- 不要求各主机时钟一致
- 每个时钟是一个二进制计数器，周期性增长；即使主机崩溃，时钟也假设持续递增
- 计数器的位数≥序列号的位数
- 连接建立时，取当前时间计数器的低k位作为起始序列号，确保每次连接用的起始序列号都不同，避免重启后使用老序号
- 序列号空间要足够大，这样即使序列号回卷，旧数据包也早就过期了
4.发送太快会导致序列号进入禁止区域；发送太慢也会导致序列号进入禁止区域
#### 方案：三次握手
防止历史连接中的延迟数据包被误认为是新连接中的合法数据，从而引发安全或协议错误
1.三次握手用于初始化数据包
①原因：当前连接并没有保存来自上一个连接的任何状态，所以双方主机都要贡献新的初始序列号
②流程：
（CR-连接请求）
<font color="#c00000">seq是自己的序号，ack是对方的序号</font>
- Host1向Host2发送一个连接请求（CR），序列号为x
- Host2回复一个ACK确认包，表示接受连接请求，并附上自己的序列号y，同时确认Host1的序列号x    
- Host1 再发出一条包含ACK的数据包，表示收到确认并附带自己的确认
2.建立连接的过程[[ch06.pdf#page=37&selection=20,0,20,53|ch06, p.37]]
三次握手协议可以防止一些奇怪的错误情况
①重复的连接请求：错误的ACK没有连接
一个过期的连接请求到达，即使Host2回复了ACK，只要Host1没有收到正确的SYN-ACK，它不会建立连接
- Host1曾在过去发过一个连接请求CR（SYN, seq=x），因为网络问题延迟，现在才被Host2收到  
- Host2以为是新连接，于是发送了ACK(seq=y, ack=x)
- 但这时Host1并没有发送新的SYN，它收到这个ACK后检查发现不匹配，直接拒绝连接
②重复的连接请求和数据：相同的数据将被拒绝（错误的ACK）
即使攻击者（或旧包）带来了数据包，因 ACK 不匹配，Host2 也会拒绝数据，防止伪造连接
- 情况同样开始于旧的CR(seq = x)被Host2收到
- Host2 回复了ACK(seq=y, ack=x）
- 但接着一个旧的数据包也跟来了：DATA(seq=x, ack=z)
- Host2会检查这个数据包的ACK值，发现不对（ack≠y），于是拒绝
#### TCP的连接建立
1.使用三次握手建立连接
- 客户端发送 SYN（请求连接）
- 服务端回应 SYN-ACK（同意连接）
- 客户端回应 ACK（确认连接）
2.设置初始序号的方法
①基于时钟机制：有可预测/重复的风险
②防止序号回绕机制PAWS：在一个连接中，TCP会使用时间戳来扩展32位的序号，防止在一个最大包生命周期内出现序号回绕的问题，即使在千兆速率的网络中也能避免。

### 6.2.3 连接释放
#### 三次握手连接释放
1.非对称释放：一方单方面中断连接
断开连接请求发出后，数据不再被传递，可能导致数据丢失[[ch06.pdf#page=40&selection=12,0,12,38|ch06, p.40]]
2.对称释放：把连接堪称两个独立的单向连接，要求每一个单向连接被单独释放
①两军队问题
②四种连接释放的协议场景
DR：释放请求
- 正常情形的三次握手[[ch06.pdf#page=42&selection=10,52,10,91|ch06, p.42]]
	- Host 1：发送DR并启动定时器
	- Host 2：收到DR→回复自己的DR并启动定时器
	- Host 1：收到Host2的DR→回复ACK（确认断开）
	- 双方都顺利断开
- 最后一个ack丢失了[[ch06.pdf#page=42&selection=12,0,12,19|ch06, p.42]]
	- Host 1 发送ACK→ACK丢失
	- Host 2 收不到ACK→等待超时后自行断开
	- 虽然 ACK 丢了，但 Host 2 的定时器起到了容错作用
- 响应丢失了[[ch06.pdf#page=42&selection=12,20,12,38|ch06, p.42]]
	- Host1发DR并启动定时器→Host2回复DR并启动定时器，但丢失
	- Host 1 超时重传 DR
	- Host 2 再次回复 DR
	- Host 1 成功收到后发出 ACK，Host 2 断开
- 响应和随后的DR都丢失了[[ch06.pdf#page=42&selection=12,39,12,82|ch06, p.42]]
	- Host 1 发 DR并启动定时器→ Host 2 回复DR并启动定时器，但丢失
	- Host 1 重传 DR 多次都丢失
	- Host 1 N 次超时后放弃并断开
	- Host 2 迟迟收不到 ACK，也等待超时才断开
### 6.2.4 错误控制和流量控制
1.错误控制：基础是有校验和+重传的滑动窗口（来自链路层）
2.流量控制：用于管理发送方与接收方的缓存协调
- 滑动窗口的大小告诉发送方：接收方还有多少缓存空间可用
- 实现了一个可变大小的滑动窗口机制
①接收方缓冲区设计的三种方式[[ch06.pdf#page=44&selection=8,0,8,39|ch06, p.44]]：
- 链式固定大小的缓冲区
- 链式可变大小的缓冲区
- 每个连接使用一个大的循环缓冲区
②工作流程[[ch06.pdf#page=45&selection=8,0,8,39|ch06, p.45]]
A申请8个缓冲区
B只有0-3这4个
A发送0、1、2，2丢失
B确认0和1，允许2-4
A发送3、4
2超时，A重传2、3、4
B确认，允许5、6
A发送5、6

潜在的死锁：需定期发送确认和缓冲区状态

| 时间点   | 事件                     | 解释                            |
| ----- | ---------------------- | ----------------------------- |
| 1-2   | 请求&分配缓冲区               | A 申请 8 个 buffer，B 允许 0~3 号数据段 |
| 3-5   | 正常发送                   | A 发送 m0~m2，填满部分 buffer        |
| 6     | ACK 回应                 | B ACK=1（已收0、1），buf=3（空出一个）    |
| 7-8   | m3、m4 发送               | A 发 m3，m4，但 m4 丢失（未被 B 收到）    |
| 9     | A 超时重传                 | A 再发 m4                       |
| 10    | B ACK = 4，buf = 0      | 全部收到了，但 buffer 被填满，A 停止       |
| 11-12 | B 应用读出数据               | B 清空部分 buffer，buf=2，A 可以继续    |
| 13-14 | A 发送 m5, m6            | 继续发送，buf 再次满                  |
| 15-16 | A 收到 ACK=6, buf=0 → 死锁 | A 等待缓冲区腾出，但 B 没释放 → 死锁风险      |
### 6.2.5 多路复用
可发生的传输层 / 网络层共享类型：
1.多路复用：多个连接共享一个网络地址
2.逆向多路复用：多个网络地址共享一个连接
### 6.2.6 崩溃恢复
1.客户端/服务端策略组合下的协议表现
①横轴：接收端的策略

|策略缩写|含义|
|---|---|
|**AC(W)**|ACK 然后写（First ACK, then Write）|
|**AWC**|ACK-Write 同时执行|
|**C(AW)**|确认整个操作|
|**C(WA)**|Write 然后 ACK（First Write, then ACK）|
|**W AC**|写入后再 ACK|
|**WC(A)**|写入 & 确认整体|
②纵轴：发送端策略

| 策略缩写                  | 含义         |
| --------------------- | ---------- |
| **Always retransmit** | 总是重传       |
| **Never retransmit**  | 从不重传       |
| **Retransmit in S0**  | 若没有未确认段才重传 |
| **Retransmit in S1**  | 若还有未确认段才重传 |
③结果：

|符号|含义|
|---|---|
|**OK**|协议正常工作，无重复、无丢失|
|**DUP**|产生了重复消息（Duplicate）|
|**LOST**|消息丢失|
2.N层崩溃后的恢复只能由N+1层完成，前提是更高层保留了足够的状态信息，能够重构问题发生前的位置
3.端到端确认：几乎不可能实现
## 6.3 拥塞控制
### 6.3.1 理想的带宽分配
#### 效率和功率
有效利用带宽，应该产生高的有效吞吐量+低时延
- 有效吞吐量=总吞吐量减去重传部分
- 功率指标：$\frac{负载}{时延}$
	- 带宽分配的最佳点就是功率达到最大值的地方
#### 最大-最小公平性
1.公平使用意味着所有的数据流都能获得带宽
2.最大最小公平性：不能在不减少其他分配不高的流的带宽的情况下，增加某一流的带宽；会让所有流平等地共享瓶颈链路的带宽
算法步骤：
- 从所有流速率为0开始
- 均匀增加各流速率，直到某条链路达到瓶颈（饱和）
- 将被限制的流固定住，不再增加
- 重复步骤 2 直到所有流都被分配完带宽
![[Pasted image 20260101144237.png]]
**练习[[ch06.pdf#page=53&selection=8,0,8,9|ch06, p.53]]**
F1：R1-R2-R3
F2：R1-R2-R5-R6
F3：R4-R5-R6
F4：R4-R5-R6
拥塞路段：R5-R6
$\therefore F2 \quad F3 \quad F4$的流量是$\frac{30}{3}=10Mbps$
$\therefore F1的流量是30-10=20Mbps$
#### 贾恩公平指数
用于衡量网络中带宽/资源分配是否公平的指标
$f(x_1,...,x_n)=\frac{(\sum_{i=1}^{n}(x_i))^2}{n\sum_{i=1}^{n}(x_i)^2}$
- 越接近1→越公平
- 越接近$\frac{1}{n}$→越不公平
#### 带宽分配的动态性需求-收敛
我们希望在流量模式发生变化时，带宽分配能够迅速收敛
### 6.3.2 调整发送速率
1.发送方可能出于不同原因需要减速
①流量控制：当接收方处理速度不够快时，发送方需减速
②拥塞控制：当网络本身速度不足时，发送方也需减速
2.网络可能使用不同的拥塞信号来通知传输端点减速/加速
- 显式-是否由网络设备直接明确告诉发送端
- 精确-信号是否具体、准确地反映了当前网络拥塞的程度

| 协议（Protocol）     | 拥塞信号（Signal）                               | 是否显式？(Explicit?) | 是否精确？(Precise?) |
| ---------------- | ------------------------------------------ | ---------------- | --------------- |
| **XCP**          | 要使用的速率（Rate to use）                        | 是（Yes）           | 是（Yes）          |
| **TCP with ECN** | 拥塞警告（Congestion warning）                   | 是（Yes）           | 否（No）           |
| **FAST TCP**     | 端到端时延（End-to-end delay）                    | 否（No）            | 是（Yes）          |
| **Compound TCP** | 丢包 & 端到端时延（Packet loss & end-to-end delay） | 否（No）            | 是（Yes）          |
| **CUBIC TCP**    | 丢包（Packet loss）                            | 否（No）            | 否（No）           |
| **传统 TCP**       | 丢包（Packet loss）                            | 否（No）            | 否（No）           |
3.不同调整策略对效率公平性的影响
如果两个流在网络发出空闲/忙碌信号时以相同方式增加或减少带宽，它们将无法收敛到公平分配。
①加性增加：每次带宽调整增加或减少固定值
②乘性调整：每次根据当前带宽乘以一个比例系数
4.AIMD：加法递增-乘法递减
能够收敛到一个既公平又高效的点
### 6.3.3 无线问题
1.问题：无线链路上的丢包通常是由于物理传输错误引起的，但不希望把这种丢包误认为是网络拥塞，否则，连接会因为错误地认为网络拥塞而不必要地减慢发送速率
2.解决方法：在链路层使用ARQ，隐藏无线链路上的错误，避免传输层误判
## 6.4 Internet传输协议：UDP
无连接不可靠协议
### 6.4.1 UDP概述
UDP是IP协议上的一个垫片协议
1.UDP头格式
各16bits
- 源端号
- 目的端号
- UDP数据报长
- UDP校验和：覆盖UDP报文段+IP的伪首部（保证端到端地址正确性）
	- 伪首部字段中某些值在传输中会变化，因此计算时被置零
2.校验和中包括的IPv4伪头格式
3.UDP应用
①简短的请求-回复应用程序（适合）
DNS（域名系统）
②长信息发送应用（不适合）
SMTP（简单邮件传输协议）
③大文件下载应用（不适合）
FTP（文件传输协议）
④实时交互应用（适合）
Skype（网络电话、视频会议）
4.一些与UDP和TCP一起使用的知名端口[[ch06.pdf#page=66&selection=8,0,10,11|ch06, p.66]]
**练习**
UDP报文头：`CB84 000D 001C 001C`
a. 源端口号是多少？  
b. 目的端口号是多少？  
c. 用户数据报的总长度是多少？  
d. 数据部分的长度是多少？  
e. 这个报文是从客户端发往服务器，还是反方向？  
f. 客户端使用的是哪种进程（协议）？

UDP报文头共8字节

| 字节偏移   | 内容                      |
| ------ | ----------------------- |
| 0~1 字节 | 源端口号（Source Port）       |
| 2~3 字节 | 目的端口号（Destination Port） |
| 4~5 字节 | 总长度（包括头部+数据）UDP Length  |
| 6~7 字节 | 校验和（Checksum）           |

a.`CB84`
b.`000D`
c.`0x001C=28bytes`-UDP包总长度（包含 8 字节头部 + 数据部分）
d.用总长度减去头部长度：28-8=20字节
e.由于目的端口是13，而这是一个知名服务端口，表示这是客户端发往服务器的请求
f.UDP端口13是标准的Daytime Protocol时间服务，用于返回当前时间
### 6.4.2 远程过程调用RPC
RPC让不同主机上的应用程序通过网络通信，就像在本地调用函数一样
1.存根：是客户端和服务端之间的中间层
- 客户端存根-将调用的函数名、参数封装成网络消息  
- 服务端存根-将收到的消息解析出函数名和参数，再调用真实函数，执行后返回结果。
1.RPC步骤
①客户调用客户存根
②客户存根将参数封装<列集>到一条消息中，然后执行一个系统调用来发送信息
③os将消息从客户主机发送到服务器主机上
④os将进来的数据包传递给服务器存根
⑤服务器存根利用散集后的参数调用服务器过程
客户端调用函数→客户端存根打包请求→通过网络传输请求数据→服务端收到请求并解包→服务端调用本地函数处理请求
2.gRPC可以使用协议缓冲作为：
- 接口定义语言IDL：用来定义服务、消息结构等
- 底层消息交换格式：传输时的序列化格式
默认情况下，gRPC使用协议缓冲来序列化结构化数据
### 6.4.3 实时传输协议
跳过
## 6.5 Internet传输协议：TCP
TCP为进程之间提供了可靠的字节流服务，是互联网的主力协议
### 6.5.1 TCP概述
跳过
### 6.5.2 TCP服务模型
1.知名端口号
许多流行的服务器程序都运行在众所周知的端口上

| 端口号 (Port) | 协议 (Protocol) | 用途 (Use)                                       |
| ---------- | ------------- | ---------------------------------------------- |
| 20, 21     | FTP           | 文件传输（File Transfer Protocol）                   |
| 22         | SSH           | 远程登录，取代 Telnet（Remote login）                   |
| 25         | SMTP          | 发送邮件（Simple Mail Transfer Protocol）            |
| 80         | HTTP          | 网页浏览（Hypertext Transfer Protocol）              |
| 110        | POP3          | 远程邮件接收（Post Office Protocol v3）                |
| 143        | IMAP          | 更强的邮件同步/远程访问（Internet Message Access Protocol） |
| 443        | HTTPS         | 安全网页服务（HTTP over SSL/TLS）                      |
| 543        | RTSP          | 媒体流控制协议（Real-Time Streaming Protocol）          |
| 631        | IPP           | 网络打印共享（Internet Printing Protocol）             |
2.使用TCP的应用程序只会看到一个字节流，而不会看到分段所对应的独立IP包
{应用层只看到完整的数据内容，不需要关心底层分段和网络传输}
### 6.5.3 TCP协议
跳过
### 6.5.4 TCP段的头
1.TCP段的结构
32bits
- 第1行
	- 源端口（16bits）
	- 目标端口（16bits）
- 第2行：序号【面向字节】（16bits）-表示该段中第一个字节的序号
- 第3行：确认号（32bits）-表示期望接收对方下一个字节的序号，而不是~~已经正确接收到的最后一节~~
- 第4行
	- TCP头长度（4bits）
	- 8个1位标志
		- ECE：当TCP接收方从网络检测到拥塞时，向TCP发送方发出ECN-Echo信号，告诉它减速
		- CWR：阻塞窗口从TCP发送方到TCP接收方的减少，以便它知道发送方已经变慢，可以停止发送ECN-Echo
		- URG：允许发送方向接收方发送信号以接受一些紧急数据，而不必让TCP本身参与中断的原因，但很少使用。Urgent指针用于指示要找到紧急数据的当前序列号的字节偏移量
		- ACK：以表明确认编号有效。这是几乎所有包的情况
		- PSH：请求接收方在数据到达时将其交付给应用程序，并且在接收到满缓冲区之前不对其进行缓冲（为了提高效率，它可能会这样做）。
		- RST：用于强制重置一个已经混乱的连接，这种情况可能由于主机崩溃或其他异常原因引起。RST还可以用于拒绝无效的数据段或拒绝建立连接的尝试。
		- SYN：建立连接
			- SYN=1，ACK=0→表示连接请求
			- SYN=1，ACK=1→表示连接应答
			- 连接请求具有SYN=1和ACK=0，表示没有使用背接确认字段。
			- 连接应答确实带有确认，因此它具有SYN=1和ACK=1。
			- SYN位用于表示连接请求和连接接受，ACK位用于区分这两种可能性
		- FIN：释放连接。它指定发送方没有更多的数据要传输。
			- 然而，在关闭连接后，关闭进程可能会无限期地继续接收数据。SYN和FIN段都有序列号，因此保证按照正确的顺序进行处理
			- TCP释放连接：4次挥手
				- A → B：发送 FIN
				- B → A：ACK
				- B → A：也发送FIN
				- A → B：ACK
	- 窗口大小（16bits）：从确认字节开始，可以继续发送的最大字节数
		- 流量控制在TCP中是通过可变大小的滑动窗口来实现的
		- 窗口大小字段为0是合法的，表示已接收到包括确认号- 1在内的字节，但接收方还没有机会消费数据，并且暂时不需要更多的数据
		- 接收方可以稍后通过发送具有相同确认号和非零窗口大小字段的段来授予发送权限
- 第5行
	- 校验和（16bits）
		- 对TCP报文的头部、数据以及一个概念上的伪首部进行校验
		- 和 UDP 的处理方式一致，但TCP的校验和是强制性的
		- 伪首部中包含的内容包括源IP地址、目标IP地址、协议号（对于TCP是6） 以及TCP长度。它并不真正出现在数据中，只是为了计算校验和而临时拼接的。
	- 紧急指针（16bits）
- 第6行：选项（0个或多个 32-bit 字），最长可以扩展到40字节
	- MSS最大段长
		- 每台主机可以声明其愿意接受的最大报文段长度
		- 在连接建立期间（三次握手过程），通信双方都会声明自己接受的最大MSS值，并可以看到对方的MSS值
		- 两个方向的MSS不一定相同：也就是说，从 A → B 和 B → A 的最大段大小可以不一样，取决于各自的网络条件和配置。
	- 窗口尺度
		- 允许发送方和接收方在连接建立初期协商一个窗口缩放因子，用以扩展TCP的窗口大小
		- 该缩放因子最多可以将窗口大小字段左移14位，从而使最大窗口达到$2^{30}$字节
	- 时间戳
		- 发送方会在报文中携带一个时间戳，接收方收到后会在回复中原样返回该时间戳
		- 一旦在连接建立期间（如三次握手）协商启用，该选项就会在后续所有报文中出现，其主要作用是帮助测量往返时间RTT，从而估算包是否丢失
		- 该时间戳还作为TCP序号（32位）的逻辑扩展使用，用于避免在高速通信中序号快速回绕的问题
	- SACK选择确认
		- 接收方可以通过SACK告诉发送方它收到了哪些特定序号范围的报文段，而不是仅通过累积确认
		- SACK是对普通ACK的补充，特别适用于如下情况：某个包丢失了，但之后的包反而先收到了（或收到了重复包），SACK 选项就能明确告诉发送方：“这些我收到了，那个丢的你再发一次。”
		- 由 RFC 2108 和 RFC 2883 定义
- 第7行：数据（可选）
2.序号&窗口大小[[ch06.pdf#page=87&selection=30,0,30,38|ch06, p.87]]
①必须确保 TCP 的序列号不会在一个报文段的最大存活时间（MSL）内回绕一圈。这取决于网络的传输速度（即带宽越大，传输越快，越容易回绕）。
②要让网络管道保持充满状态，就必须让窗口大小至少等于带宽与延迟的乘积
带宽延迟积=延迟×RTT

【根据带宽计算32位的TCP序列号全部用完所需的时间】
$TCP序号空间=2^{32}bytes=2^{35}bits$
$带宽：OC-48=2.5Gbps=2.5*10^9bps$
$用完所需的时间=\frac{2^{35}bits}{2.5*10^{9}bps}=34.4s$
【单位换算】

| 单位     | 等价 bit                       |
| ------ | ---------------------------- |
| 1 kbps | 1,000 bps                    |
| 1 Mbps | 1,000,000 bps = ($10^6$)     |
| 1 Gbps | 1,000,000,000 bps = ($10^9$) |
| 1 Tbps | ($10^{12}$) bps              |

| 单位   | 等价 Byte（按 2 进制）        |
| ---- | ---------------------- |
| 1 KB | (1,024 = $2^{10}$) B   |
| 1 MB | (1,024^2 = $2^{20}$) B |
| 1 GB | (1,024^3 = $2^{30}$) B |
| 1 TB | ($2^{40}$) B           |

**练习1**
假设TCP在一个速率为40-Gbps的STS-768链路上运行。
(a)假设TCP能够持续利用全部带宽，序列号完全绕回需要多长时间？
完全绕回：从0增加到最大值再回到0
$B=40Gbps=40*10^9bps=4*10^{10}bps$
$序号空间=2^{35}bit$
$用完所需的时间=\frac{2^{35}}{4*10^{10}}=\frac{2^{33}}{10^{10}}\approx 859ms$

(b)假设增加了一个32位的时间戳字段，该字段在上述 (a) 问计算出的绕回时间内发生了1000次递增。那么该时间戳字段绕回需要多长时间
1tick时间：$\frac{859ms}{1000}=0.859ms$
$2^{32}$个tick：$2^{32}*0.859ms\approx 43天$
【当时间戳从0一直递增到$2^{32}-1$后，再增加一次，它就会回绕到0】

**练习2**
你被聘请设计一种可靠的字节流协议，它使用滑动窗口机制（如TCP）。该协议将在 1-Gbps 的网络上运行。网络的 RTT 是 140ms，最大段生命周期为 60 秒。你会在协议头部为 AdvertisedWindow 和 SequenceNum 字段各预留多少位？
`AdvertisedWindow`-接收方的接收窗口大小
`SequenceNum`-TCP序号
$B=1Gbps=10^9bps$
$RTT=0.14s$
$T=60s$
①$B*RTT=10^9*0.14=1.4*10^8bits$
<span style="background:rgba(3, 135, 102, 0.2)">TCP协议中的所有数据单位都是以字节为基础的</span>
$\frac{1.4*10^8}{8}bits=17.5*10^6B=17.5MB=17.5*2^{20}\approx2^{25}byte$
$\therefore n_{min}=25$

②【最大可用序号≥最多可能传输的总字节数】
<span style="background:rgba(3, 135, 102, 0.2)">在最大segment生命周期内不能用完一轮序号</span>
$最大生命周期内最多能发送的数据=1*60=60Gb=\frac{60}{8}GB=7.5GB=7.5*2^{30}B\approx2^{33}B$
$\therefore n_{min}=33$

### 6.5.5 TCP连接建立
#### 三次握手
- 建立连接请求使用SYN标志，表示同步序号
- 断开连接请求使用FIN标志，表示完成连接
1.正常情况下的TCP连接建立过程
seq-递增
ack=对方的seq+1
2.双方同时尝试建立连接的情况
seq-不变
ack=对方的seq+1
#### 建立过程
- 发起连接的一方称为主动打开
- 被动等待连接的一方称为被动打开
#### 数据传输过程
全双工
### 6.5.6 TCP连接释放
对称释放
1.三次挥手
FIN：不在发送数据，而不是~~立刻释放连接~~
2.四次挥手
半关闭-连接一端关闭，另一端保持开放
第二个包：seq=y，ack=x+1
### 6.5.7 TCP连接管理模型
1.TCP连接管理有限状态机的状态[[ch06.pdf#page=95&selection=8,0,10,8|ch06, p.95]]

|英文状态名|中文翻译|含义说明|
|---|---|---|
|**CLOSED**|已关闭|没有任何连接是活动状态，也没有挂起的连接。TCP 初始状态或连接完全终止后的状态。|
|**LISTEN**|监听中|服务器端监听端口，等待客户端发起连接请求（SYN）。典型于 `server.listen()` 时进入该状态。|
|**SYN RCVD**|收到SYN|收到对方的连接请求（SYN），并发回确认（ACK），现在等待对方再回一个 ACK 完成三次握手。|
|**SYN SENT**|已发送SYN|主动发起连接的一方（通常是客户端）发送了 SYN 报文，正在等待服务器回应 ACK。|
|**ESTABLISHED**|已建立连接|三次握手完成，连接建立，可以进行双向数据传输了，这是 TCP 中“传输进行中”的状态。|
|**FIN WAIT 1**|等待对方关闭（阶段1）|应用层调用 `close()`，TCP 发送 `FIN` 报文，表示我这边不再发送数据了，等待对方确认。|
|**FIN WAIT 2**|等待对方关闭（阶段2）|收到对方对 `FIN` 的 ACK，进入 `FIN_WAIT_2`，此时仍然可以接收对方的数据。|
|**TIME WAIT**|时间等待|自己是最后一个发送 `ACK` 的一方（即主动关闭的一方），进入该状态以等待一定时间（如 2MSL），确保对方收到 ACK，防止旧连接报文干扰新连接。|
|**CLOSING**|双方同时关闭|非常罕见的状态：双方几乎同时调用 `close()` 并发送 `FIN`，因此需要双方互相确认的过程。|
|**CLOSE WAIT**|等待自己关闭|对方先发送了 `FIN`，这边已收到（并发了 ACK），表示对方不会再发数据了，等待我方程序也调用 `close()`。|
|**LAST ACK**|最后确认|自己已调用 `close()`，发出 `FIN` 后，等待对方 ACK，然后进入 `CLOSED` 状态。通常由被动关闭方进入此状态。|
2.TCP连接管理有限自动机[[ch06.pdf#page=96&selection=8,0,10,8|ch06, p.96]]
3.典型的TCP连接生命周期：建立连接（三次握手）→数据传输→连接终止（四次挥手）[[ch06.pdf#page=97&selection=8,0,8,17|ch06, p.97]]
### 6.5.8 TCP滑动窗口
TCP位滑动窗口添加流量控制：
1.发送者的限制=ACK+WIN
发送方最远能发送的数据=接收方确认的最后字节号+告知可接收的窗口大小
win=0表示发送方暂时无法向接收方继续发送数据
2.傻瓜窗口症状：由于接收端或发送端处理不当，导致TCP频繁地发送极小的数据段，浪费带宽，效率极低。
### 6.5.9 TCP计时器管理
TCP根据段的RTT估计重传定时器
超时重传的时间设置为RTT估计平均值+4×方差
### 6.5.10 TCP拥塞控制
1.TCP 利用加性增大乘性减小（AIMD）算法配合丢包信号来控制拥塞
机制：

|名称（Name）|机制（Mechanism）|目的（Purpose）|
|---|---|---|
|**ACK clock**|利用**拥塞窗口 cwnd**控制发送速率|平滑数据包的突发发送|
|**慢启动（Slow-start）**|每个RTT使 cwnd **翻倍**|**快速探测带宽上限**，让发送速率快速增长|
|**加性增加（Additive Increase）**|每个RTT让 cwnd **+1个包**|**缓慢增长发送速率**，以免网络突然拥塞|
|**快速重传 / 快速恢复**（Fast retransmit / recovery）|收到**3个重复ACK**就立刻重传丢失的数据包，且为每个ACK发送一个新包|**无需等待超时**就能重传，提高效率，并且**不停止ACK时钟**|
2.拥塞窗口控制发送速率
①$v=\frac{cwnd}{RTT}$
②ACK时钟（即规律到达的ACK）能节奏性地调控发送行为，平滑突发的数据流
e.g.
发送端在带宽较大的“快速链路”上一口气发送了一串数据包（突发流量）
→这些数据包被“路由器缓冲区”暂时排队等待，然后一个个被送入下游的“慢速链路”（瓶颈）
→接收端处理完数据包后发出 ACK，由于链路慢，这些 ACK 以固定速率返回发送端
→发送端收到 ACK 后，根据每一个 ACK 再发一个新数据包，这样一来，ACK 的返回速率就决定了发送速率，形成所谓的ACK Clock
3.慢启动[[ch06.pdf#page=103&selection=8,0,8,31|ch06, p.103]]
以指数方式增长拥塞窗口
- 在维持ACK时钟运行的同时，每经过一次RTT，cwnd值翻倍
- 每收到一个新的ACK，cwnd就加1
- 从初始的1个段开始慢启动过程
即：
- 每轮RTT发送的数据包数≈当前cwnd
- 每个数据包收到ACK→cwnd加1
<font color="#c00000">【在每个RTT内会有cwnd个ack到达，每到达一个ack，cwnd+=1】</font>
e.g.
RTT 1：
- cwnd = 1，发送一个数据段
- 收到 1 个 ACK → cwnd 增加到 2
RTT 2：
- cwnd = 2，连续发送 2 个段
- 每个段收到 ACK → cwnd 增加 3 → 总变为 4
RTT 3：
- cwnd = 4，发送 4 个段    
- 每个段收到 ACK → cwnd 增加 4 → 总变为 8
RTT 4：
- cwnd = 8，再发送 8 个段（这里只画了 4 个，表示管道“已满”）
- 若网络没丢包，将继续指数增长（下一轮 16）

| 时刻   | cwnd 值 | 这一轮能发的包数 | 收到 ACK 后加了多少 | 下一轮 cwnd |
| ---- | ------ | -------- | ------------ | -------- |
| 初始   | 1      | 1        | +1           | 2        |
| RTT1 | 2      | 2        | +2           | 4        |
| RTT2 | 4      | 4        | +4           | 8        |
| RTT3 | 8      | 8        | +8           | 16       |
4.加性增加机制[[ch06.pdf#page=104&selection=8,0,8,31|ch06, p.104]]
- 以较慢的速度增长拥塞窗口
- 每经过一个往返时间（RTT），cwnd增加1个报文段
- 保持 ACK 时钟（即通过接收到的 ACK 报文来驱动发送）
5.TCP Tahoe：慢启动后跟随加性增加[[ch06.pdf#page=105&selection=8,0,8,31|ch06, p.105]]
【发生丢包时，直接回退 cwnd = 1，再次慢启动】
阈值 ssthresh 设置为发生丢包时拥塞窗口 cwnd 的一半
前期（RTT 0–6）：
- 初始阶段使用慢启动
- 拥塞窗口指数增长，直到达到阈值32KB
- 这时ssthresh=32KB，进入拥塞避免阶段
中期（RTT 6–13）：
- 进入加性增加阶段
- 拥塞窗口以线性增长（每 RTT 增加 1）继续增加
丢包点（RTT 13）：
- 发生了丢包
- 由于 ACK 时钟停止（说明没有再收到 ACK）→ 被视为超时（timeout）
- 于是：
    - 将ssthresh 设置为当前cwnd的一半  
    - cwnd重置为1
    - 重新开始慢启动
后期（RTT 14–22）：
- 从 cwnd = 1 开始重新慢启动
- 达到 ssthresh（20KB）后转为加性增加
- 再次进入线性增长阶段
``` c
// 当收到新的 ACK 时：
if (cwnd < ssthresh)
    cwnd += 1            // 还在慢启动阶段
else
    cwnd += 1 / cwnd     // 拥塞避免阶段（近似每 RTT 增加 1）

// 当发生 timeout 或 3 次重复 ACK（表示丢包）时：
retransmit all unacked  // 重传所有未确认的数据
ssthresh = cwnd / 2     // 将阈值设为当前 cwnd 的一半
cwnd = 1                // 拥塞窗口重置为 1（重新慢启动）

```
6.改进-TCP Reno拥塞控制机制[[ch06.pdf#page=106&selection=8,0,8,31|ch06, p.106]]
- 收到3个重复ACK后立即重传丢失数据包
- 每收到一个重复ACK就发送一个新数据包，直到丢包被确认修复
阶段一：慢启动
- 从 cwnd = 1 开始    
- 拥塞窗口指数增长，直到阈值（ssthresh）= 32KB
阶段二：加性增加
- 达到阈值后，TCP 进入拥塞避免
- 拥塞窗口线性增长，每 RTT 增加 1
阶段三：丢包检测（通过重复 ACK）
- 第一次丢包发生在 RTT ≈ 14 时  
- 收到 3 个重复 ACK，说明某个包可能丢失但网络还在传输 → Fast Retransmit  
- 进入 Fast Recovery 阶段：
    - 立即重传丢失的第一个未确认的数据包
    - 设置 `ssthresh = cwnd / 2`
    - 设置 `cwnd = ssthresh`（不是变回 1）
- 继续发送新包，不中断 ACK 时钟 `
阶段四：再次 Additive Increase → 又丢包
- 再次出现丢包时（RTT ≈ 31）触发相同逻辑
- 出现锯齿状图形，正是 Reno 的特征
``` c
// 正常 ACK 到达：
if (cwnd < ssthresh)
    cwnd += 1          // 处于慢启动
else
    cwnd += 1/cwnd     // 拥塞避免，每 RTT 增加约 1

// 收到 3 个重复 ACK：
fast retransmit         // 快速重传首个未确认包
ssthresh = cwnd / 2     // 将阈值设为 cwnd 一半
cwnd = cwnd / 2         // 拥塞窗口减半，继续通信

// 如果是 timeout（没有任何 ACK）：
retransmit first unacked // 重传首个未确认包
ssthresh = cwnd / 2      // 阈值减半
cwnd = 1                 // 回到慢启动

```
7.SACK选择重传
- 在原有ACK基础上扩展为一个向量，能够描述哪些数据段已成功接收，从而也间接指出哪些数据丢失了,因此发送方可以更加准确地重传丢失的数据，提高恢复效率
- 每个SACK块说明已经成功收到的范围
【总结】
- TCP Tahoe：在超时重传和收到3个重复ACK时，都将拥塞窗口CWND设置为1
- TCP Reno 
	- 超时-CWND归1
	- 收到3个重复ACK-将CWND减半，进入快速恢复
- TCP-newReno：在 Reno 基础上，改进了快速恢复机制
- TCP-SACK：引入了选择性确认机制
#### 显式拥塞通知ECN 
- 连接建立期间，发送方与接收方通过设置 ECE 和 CWR 位，表明它们都支持 ECN 功能
- 每个携带 TCP 段的数据包，其IP 头中会标记 ECN 相关位，表明它可以承载拥塞信号。当网络拥塞即将发生时，路由器会设置 ECN 标志位来发出警告，而不是等到真正拥塞后直接丢包
- 如果某个到达的包中包含 ECN 拥塞标记，接收方会检测到这一点，然后在返回的 ACK 中设置ECE 标志位，通知发送方“你发的包遇到过拥塞”
- 发送方在收到 ECE 后，会通过设置CWR 标志位来告知接收方“我已收到拥塞通知，并已减小拥塞窗口”。TCP 发送方将 ECN 视为与“丢包引起的重复 ACK”一样重要，并作出相同响应（如减小窗口），但相比丢包，这种方式更优雅，因为没有包真的被丢弃。ECN 的详细定义见RFC 3168。
``` markdown
双方建立连接时：都表明支持 ECN（ECE/CWR）    
         ↓
发送的数据包打上 ECN 可用标记（ECT）    
         ↓
如果路由器发现快要拥塞：打上 CE（拥塞遇到）    
         ↓
接收方发现 CE，返回 ACK 时设置 ECE（回声）    
         ↓
发送方收到 ECE → 调整拥塞窗口 → 回 ACK 设置 CWR

```
### 6.5.11 TCP CUBIC
根据距离上一次重复ACK所经历的时间来调整拥塞窗口
更适合大BDP网络
## 6.6 传输协议与拥塞控制
### 6.6.1 QUIC：快速UDP互联网连接
1.QUIC是一种运行在UDP之上的传输协议，旨在改善TCP的吞吐量和延迟特性，从而让Web等应用层协议运行得更快
- 目标：多个连接复用在单一的UDP流中，同时确保某个Web对象传输被延迟时，不会阻塞其他对象的传输
- 如果某个流中丢失了数据，QUIC协议仍可独立地传输其他流的数据，从而提高高误码率链路下的性能表现
2.QUIC还通过多种优化手段进一步提升性能
- 在传输连接建立时，顺带传输应用层加密信息
- 每个数据包都独立加密，因此即使一个包丢失，也不会影响后续包的解密
- 提升网络切换时的速度（例如从蜂窝网切换到 Wi-Fi）
- 使用连接 ID 来维持连接状态，即使终端切换了网络也能继续通信
### 6.6.2 BBR：基于瓶颈带宽的拥塞控制
1.问题：缓冲区膨胀-网络路径上的设备（如路由器）拥有过大的缓冲区，这会让 TCP 发送方在拥塞窗口很大时，发送数据的速率远远超过了网络的实际承载能力，却迟迟收不到丢包信号，导致错误判断网络状况良好，继续高速发送。

中间网络节点的缓冲区被填满后：
- 拥塞事件被延迟检测
- 那些继续发送的主机不会意识到拥塞，导致延迟增加
- 后续的包被排在队尾，排队时延严重上升
2.解决方法：
- 直接减小设备缓冲区大小：
- 设计非基于丢包的拥塞控制算法-BBR
3.BBR：持续追踪网络中的瓶颈带宽（即最小带宽段）和往返传播时延
①计算瓶颈带宽：BBR 把最近一段时间（通常为 6-10 个 RTT）中观察到的最大送达速率作为当前瓶颈带宽的估计值。
②最优运行点：当增加在途数据量开始导致RTT增加、但送达速率不再上升时，这个点就是BBR的最佳运行点
### 6.6.3 TCP的未来

## 6.7 性能问题
跳过
